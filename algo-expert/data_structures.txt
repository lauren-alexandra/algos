Data Structures

- Coding is manipulating data to accomplish something.
- Data structures are a way to organize and manage data. 
- A data structure is a collection of data values, the 
relationships among them, and the functions or operations 
that can be applied to the data. 

Complexity Analysis 

- a problem can have multiple solutions, but some are better than others
- the bedrock of coding interviews
- time complexity
	- measure of how fast an algorithm runs
- space complexity 
	- how much memory or space an algorithm uses up 
- referred together as space-time complexity
- different data structures are going to have different
time and space complexity ramifications

Memory

- why is space important? memory is not unlimited. 
- comprised of bits, 0s and 1s. 8 bits = byte.
- byte e.g. 0000 0001 
- this is (2^7 2^6 2^5 2^4  2^3 2^2 2^1 2^0) binary number format (base-2 format)
- 256 possible values in a byte
- how to store more than value 256? increase the number of bits
that are stored in a data value. for 16- or 32- or 64-bit 
architecture 
- can point to another memory address from current memory address.
this is a pointer.
- a list of items needs to be stored back-to-back in memory slots
that must be free

Big O Notation

Time complexity: measuring the change in speed of the algorithm with respect to the size of the input. 
Asymptotic analysis: study the behavior of a function f(n) as the value n moves towards infinity. 

Best to worst complexity (given the worst-case scenario): 
O(1) Constant Time. Meaning N/space is irrelevant to performance.
O(log(N))
O(N) Linear Time Complexity. As size of N input increases, the speed of the algorithm increases linearly. Every single element traversed through.
O(2N) = O(N) 
O(N log(N)) 
O(N^2).    Every single element traversed through twice. 
O(N^3).
O(N^4 + N^2) = O(N^4) 
O(2^N) 
O(N!) // N factorial 

note: if have two inputs: O(N + M) for example. 

Logarithm 

log sub b (x) = y iif b^y = x 

- the log of the number X given a base b is equal to y 
"aka what is the exponent/power needed to get x value if starting with b value"
if and only if 
b to the power of y is equal to x 

we always assume that we are dealing with base 2 unless otherwise specified.
binary logarithm.
e.g.
read "log base 2 of (N) is equal to y iif 2^y = N"
because we can assume: "log of N equals y if and only if 2 to the power of y equals N"

whenever you increase the y exponent, you are doubling N (given base 2) 
e.g. 2^2 = 4, 2^3 = 8....

--> This means as the input increases, as the input doubles, the number y of elementary
operations we are performing in the algorithm only increases by 1. 
A log(N) complexity is much better than linear complexity which would increase by 
N operations as the input increases.

--> As the input doubles in size, we only do one additional operation. This is 
a time complexity of log(N) "log of N". 


Strings

- differ a bit given programming language
- a string is stored in memory as an array of integers where each character is mapped 
to an integer using an encoding standard like ASCII, e.g. A => 65.
- traversing a string is O(N) in Time Complexity and O(1) Space Complexity operation
- copy a string is O(N) in space time complexity
- getting a string is O(1) in space time complexity 


Stacks and Queues

Stack. Think of a book stack. Stacking a book on top and then removing it would mean
the book is last in, first out LIFO. 

Queue. Think of people waiting in line to order coffee. The first person in line will
be the first person to order coffee. First in, first out. FIFO.

Insertions and deletions in stacks and queues run in constant space time O(1)
Searches are O(N) time and constant space O(1) 
To store data O(N) space


Hash Tables

- A key/value store 
- Searching for a value, inserting, and deleting given a key runs on constant time O(1)
  on average 
- under the hood of a hash table is an array. a key, a string, is transformed by a hash 
  function into a index.  
- the hash function find the ascii value for each character in a string e.g. "foo" and
  adds them up. e.g. 301. This number is used to find the index using the modulo operator
  and the length of the underlying array (hash table). e.g. if the array is length 3, then
  301 % 3. This is equal to 1. So the key "foo" would be transformed into index 1. 
- what happens if two or more keys are transformed into the same index? then you get 
  a linked list. e.g. given a hash table:

  "abc" => 1  // goes through hash function: 302 % 3 === 2
  "def" => 2  // goes through hash function: 302 % 3 === 2
  "ghi" => 3  // goes through hash function: 300 % 3 === 0

            [ ,  ,  ]
   "ghi" <-- 3	   1 --> "abc"
                   |		// this is a linked list
                   +
	           2 --> "def" 

- Searching for a value, inserting, and deleting given a key runs on constant time O(N)
  on worst case. That is if all the key values have the same index under the hood, 
  then you have a linked list the same length as the hash table. 



















